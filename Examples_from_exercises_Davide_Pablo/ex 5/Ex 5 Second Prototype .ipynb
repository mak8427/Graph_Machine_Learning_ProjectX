{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T21:32:24.552524Z",
     "start_time": "2024-11-25T21:20:23.682416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch_geometric as pyg\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "import torch.nn as nn\n",
    "from torch_geometric.utils import to_networkx, subgraph\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ensure reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# GINE Layer with Virtual Nodes\n",
    "class GINELayerWithVN(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, edge_dim):\n",
    "        super(GINELayerWithVN, self).__init__(aggr='add')  # \"Add\" aggregation.\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(out_channels, out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(out_channels, out_channels)\n",
    "        )\n",
    "        self.edge_encoder = torch.nn.Linear(edge_dim, out_channels)\n",
    "        # Remove node_encoder from here\n",
    "        self.virtual_node_mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(out_channels, out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(out_channels, out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.edge_encoder.weight)\n",
    "        for m in self.mlp:\n",
    "            if isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "        for m in self.virtual_node_mlp:\n",
    "            if isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, vn_embed, batch):\n",
    "        # x is already encoded via node_encoder in the main model\n",
    "        x = x.float()  # Ensure x is FloatTensor\n",
    "        edge_attr = edge_attr.float()  # Ensure edge_attr is FloatTensor\n",
    "        edge_attr = self.edge_encoder(edge_attr)\n",
    "\n",
    "        # Add virtual node embedding to node features\n",
    "        vn_expanded = vn_embed[batch]\n",
    "        x = x + vn_expanded\n",
    "\n",
    "        # Message Passing\n",
    "        out = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "        # Update node embeddings\n",
    "        out = self.mlp(out)\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        # Compute messages\n",
    "        return x_j + edge_attr\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out\n",
    "\n",
    "# Laplacian Positional Encodings (LapPE)\n",
    "def compute_laplace_pe(data, num_eigenvec=10):\n",
    "    G = to_networkx(data, to_undirected=True)\n",
    "    A = nx.adjacency_matrix(G).astype(float)\n",
    "    num_nodes = A.shape[0]\n",
    "    D = np.diag(np.array(A.sum(axis=1)).flatten())\n",
    "    L = D - A.todense()\n",
    "    L = torch.tensor(L, dtype=torch.float, device=device)\n",
    "    try:\n",
    "        eigenvalues, eigenvectors = torch.linalg.eigh(L)\n",
    "    except RuntimeError:\n",
    "        eigenvalues, eigenvectors = torch.symeig(L, eigenvectors=True)\n",
    "    available_eigenvec = eigenvectors.shape[1] - 1\n",
    "    actual_num_eigenvec = min(num_eigenvec, available_eigenvec)\n",
    "    eigenvectors = eigenvectors[:, 1:1 + actual_num_eigenvec]\n",
    "    if actual_num_eigenvec < num_eigenvec:\n",
    "        pad_size = num_eigenvec - actual_num_eigenvec\n",
    "        padding = torch.zeros(eigenvectors.shape[0], pad_size, device=device)\n",
    "        eigenvectors = torch.cat([eigenvectors, padding], dim=1)\n",
    "    return eigenvectors  # Shape: (num_nodes, num_eigenvec)\n",
    "\n",
    "# Random Walk Structural Embeddings (RWSE)\n",
    "def compute_rwse(data, walk_length=10):\n",
    "    G = to_networkx(data, to_undirected=True)\n",
    "    A = nx.adjacency_matrix(G).astype(float)\n",
    "    A = A.todense()\n",
    "    num_nodes = A.shape[0]\n",
    "    A = torch.tensor(A, dtype=torch.float, device=device)\n",
    "    rw_features = []\n",
    "    A_power = A.clone()\n",
    "    for _ in range(walk_length):\n",
    "        diag = torch.diagonal(A_power)\n",
    "        rw_features.append(diag)\n",
    "        A_power = torch.matmul(A_power, A)\n",
    "    rwse = torch.stack(rw_features, dim=1)  # (num_nodes, walk_length)\n",
    "    return rwse  # Shape: (num_nodes, walk_length)\n",
    "\n",
    "# SignNet to ensure sign invariance\n",
    "class SignNet(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(SignNet, self).__init__()\n",
    "        self.phi = nn.Sequential(\n",
    "            nn.Linear(in_dim, out_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.phi(x) + self.phi(-x)\n",
    "\n",
    "# Graph Transformer Layer with Masking\n",
    "class GraphTransformerLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, num_heads=4, dropout=0.1):\n",
    "        super(GraphTransformerLayer, self).__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim=in_dim, num_heads=num_heads, dropout=dropout)\n",
    "        self.linear1 = nn.Linear(in_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(out_dim, in_dim)\n",
    "        self.norm1 = nn.LayerNorm(in_dim)\n",
    "        self.norm2 = nn.LayerNorm(in_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, key_padding_mask=None):\n",
    "        # x: (sequence_length, batch_size, embed_dim)\n",
    "        attn_output, _ = self.self_attn(x, x, x, key_padding_mask=key_padding_mask)\n",
    "        x = x + attn_output\n",
    "        x = self.norm1(x)\n",
    "        linear_output = self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
    "        x = x + linear_output\n",
    "        x = self.norm2(x)\n",
    "        return x\n",
    "\n",
    "# Updated GNN Model with Virtual Node, GINE Layers, and Graph Transformer\n",
    "class GNNWithVirtualNodeAndGINEAndTransformer(torch.nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, edge_attr_dim, num_layers=5, lap_pe_dim=10, rwse_dim=10):\n",
    "        super(GNNWithVirtualNodeAndGINEAndTransformer, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_features = hidden_features\n",
    "\n",
    "        # Node Encoder\n",
    "        self.node_encoder = nn.Linear(in_features, hidden_features)\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            self.convs.append(GINELayerWithVN(\n",
    "                in_channels=hidden_features,\n",
    "                out_channels=hidden_features,\n",
    "                edge_dim=edge_attr_dim\n",
    "            ))\n",
    "\n",
    "        self.virtual_node_embedding = torch.nn.Embedding(1, hidden_features)\n",
    "        torch.nn.init.constant_(self.virtual_node_embedding.weight.data, 0)\n",
    "\n",
    "        self.mlp_virtual_node = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_features, hidden_features),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_features, hidden_features),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Positional Encodings\n",
    "        self.lap_pe_dim = lap_pe_dim\n",
    "        self.rwse_dim = rwse_dim\n",
    "        self.lap_pe_linear = nn.Linear(hidden_features, hidden_features)\n",
    "        self.rwse_linear = nn.Linear(rwse_dim, hidden_features)\n",
    "        self.signnet = SignNet(lap_pe_dim, hidden_features)\n",
    "\n",
    "        # Graph Transformer\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            GraphTransformerLayer(hidden_features, hidden_features) for _ in range(3)\n",
    "        ])\n",
    "\n",
    "        self.fc = torch.nn.Linear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch, data):\n",
    "        # Apply node_encoder first\n",
    "        x = self.node_encoder(x)  # [num_nodes, hidden_features]\n",
    "        # Initialize positional encodings tensor\n",
    "        pos_enc = torch.zeros_like(x).to(device)  # [num_nodes, hidden_features]\n",
    "\n",
    "        # Iterate over each graph in the batch\n",
    "        num_graphs = batch.max().item() + 1\n",
    "        for graph_id in range(num_graphs):\n",
    "            mask = (batch == graph_id)\n",
    "            num_nodes_graph = mask.sum().item()\n",
    "\n",
    "            # Extract node indices for the current graph\n",
    "            node_idx = torch.where(batch == graph_id)[0]\n",
    "\n",
    "            # Extract subgraph using pyg.utils.subgraph\n",
    "            sub_edge_index, sub_edge_attr = pyg.utils.subgraph(\n",
    "                node_idx,\n",
    "                edge_index,\n",
    "                edge_attr,\n",
    "                relabel_nodes=True,\n",
    "                num_nodes=x.size(0)\n",
    "            )\n",
    "\n",
    "            # Create sub_data\n",
    "            sub_data = pyg.data.Data(\n",
    "                x=x[node_idx],\n",
    "                edge_index=sub_edge_index,\n",
    "                edge_attr=sub_edge_attr\n",
    "            )\n",
    "\n",
    "            # Compute Positional Encodings for the sub-graph\n",
    "            lap_pe = compute_laplace_pe(sub_data, num_eigenvec=self.lap_pe_dim)\n",
    "            rwse = compute_rwse(sub_data, walk_length=self.rwse_dim)\n",
    "\n",
    "            # Apply SignNet to LapPE\n",
    "            lap_pe = self.signnet(lap_pe)  # [num_nodes_graph, hidden_features]\n",
    "\n",
    "            # Linear transformation\n",
    "            lap_pe = self.lap_pe_linear(lap_pe)  # [num_nodes_graph, hidden_features]\n",
    "            rwse = self.rwse_linear(rwse)        # [num_nodes_graph, hidden_features]\n",
    "\n",
    "            # Combine positional encodings\n",
    "            graph_pos_enc = lap_pe + rwse  # [num_nodes_graph, hidden_features]\n",
    "\n",
    "            # Assign to pos_enc\n",
    "            pos_enc[node_idx] = graph_pos_enc  # [num_nodes, hidden_features]\n",
    "\n",
    "        # Add positional encodings to node features\n",
    "        x = x + pos_enc  # [num_nodes, hidden_features]\n",
    "\n",
    "        # Initialize virtual node embedding\n",
    "        batch_size = num_graphs\n",
    "        vn_embed = self.virtual_node_embedding.weight.repeat(batch_size, 1)  # [batch_size, hidden_features]\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index, edge_attr, vn_embed, batch)  # [num_nodes, hidden_features]\n",
    "            x = F.relu(x)\n",
    "\n",
    "            # Update virtual node embedding\n",
    "            vn_aggr = global_mean_pool(x, batch)  # [batch_size, hidden_features]\n",
    "            vn_embed = vn_embed + self.mlp_virtual_node(vn_aggr)  # [batch_size, hidden_features]\n",
    "\n",
    "        # Prepare for Graph Transformer\n",
    "        # Group node features by graph and pad\n",
    "        x_padded, mask = pyg.utils.to_dense_batch(x, batch)  # x_padded: [batch_size, max_num_nodes, hidden_features]\n",
    "\n",
    "        # Transpose to match expected input of Transformer\n",
    "        x_padded = x_padded.transpose(0, 1)  # x_padded: [max_num_nodes, batch_size, hidden_features]\n",
    "\n",
    "        # mask remains of shape [batch_size, max_num_nodes], which matches key_padding_mask\n",
    "        # Invert mask for key_padding_mask (True indicates positions to be masked)\n",
    "        key_padding_mask = ~mask  # [batch_size, max_num_nodes]\n",
    "\n",
    "        # Apply Transformer layers\n",
    "        for transformer in self.transformer_layers:\n",
    "            x_padded = transformer(x_padded, key_padding_mask=key_padding_mask)\n",
    "\n",
    "        # Transpose back\n",
    "        x_padded = x_padded.transpose(0, 1)  # x_padded: [batch_size, max_num_nodes, hidden_features]\n",
    "\n",
    "        # Flatten x_padded back to x\n",
    "        x = x_padded[mask]  # x: [num_nodes, hidden_features]\n",
    "\n",
    "        # Apply global mean pooling\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_features]\n",
    "        x = self.fc(x)  # [batch_size, out_features]\n",
    "        return x\n",
    "\n",
    "# Training and evaluation functions\n",
    "def train(model, loader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(loader, desc='Training'):\n",
    "        batch = batch.to(device)\n",
    "        batch.x = batch.x.float()  # Convert node features to float\n",
    "        batch.edge_attr = batch.edge_attr.float()  # Convert edge attributes to float\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch, batch)\n",
    "        loss = loss_fn(out, batch.y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    average_loss = total_loss / len(loader)\n",
    "    return average_loss\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='Evaluating'):\n",
    "            batch = batch.to(device)\n",
    "            batch.x = batch.x.float()  # Convert node features to float\n",
    "            batch.edge_attr = batch.edge_attr.float()  # Convert edge attributes to float\n",
    "            out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch, batch)\n",
    "            y_pred.append(out.cpu())\n",
    "            y_true.append(batch.y.cpu())\n",
    "    y_true = torch.cat(y_true, dim=0).numpy()\n",
    "    y_pred = torch.cat(y_pred, dim=0).numpy()\n",
    "    # Compute per-class AP\n",
    "    ap_per_class = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        try:\n",
    "            ap = average_precision_score(y_true[:, i], y_pred[:, i])\n",
    "        except ValueError:\n",
    "            ap = 0.0  # Handle cases where a class has no positive samples\n",
    "        ap_per_class.append(ap)\n",
    "    mean_ap = np.mean(ap_per_class)\n",
    "    return mean_ap\n",
    "\n",
    "def plot_results(epochs, train_losses, val_aps, learning_rates=None):\n",
    "    epochs_range = range(1, epochs + 1)\n",
    "\n",
    "    # Plot Training Loss\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs_range, train_losses, label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('Training_Loss.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Validation AP Score\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs_range, val_aps, label='Validation AP Score', color='orange')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Precision Score')\n",
    "    plt.title('Validation AP Score over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('Validation_AP_Score.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Learning Rate if provided\n",
    "    if learning_rates is not None:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(epochs_range, learning_rates, label='Learning Rate', color='green')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Learning Rate')\n",
    "        plt.title('Learning Rate over Epochs')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig('Learning_Rate.png')\n",
    "        plt.show()\n",
    "\n",
    "def main(epochs=100, lr=0.001, hidden_features=256):\n",
    "    # Compute edge_attr_dim and num_tasks from the dataset\n",
    "    edge_attr_dim = dataset[0].edge_attr.shape[1]\n",
    "    num_tasks = dataset[0].y.shape[-1]\n",
    "\n",
    "    # Initialize the model, optimizer, and loss function\n",
    "    model = GNNWithVirtualNodeAndGINEAndTransformer(\n",
    "        in_features=dataset.num_node_features,\n",
    "        hidden_features=hidden_features,\n",
    "        out_features=num_tasks,\n",
    "        edge_attr_dim=edge_attr_dim,\n",
    "        num_layers=5,  # Increased depth as per the paper's suggestion\n",
    "        lap_pe_dim=10,\n",
    "        rwse_dim=10\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.9, patience=10)\n",
    "\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Lists to store losses and AP scores\n",
    "    train_losses = []\n",
    "    val_aps = []\n",
    "    learning_rates = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        train_loss = train(model, train_loader, optimizer, loss_fn)\n",
    "        val_ap = evaluate(model, val_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        val_aps.append(val_ap)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        learning_rates.append(current_lr)\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Validation AP Score: {val_ap:.4f}, Learning Rate: {current_lr:.6f}\")\n",
    "        scheduler.step(val_ap)\n",
    "\n",
    "    # Final test evaluation\n",
    "    test_ap = evaluate(model, test_loader)\n",
    "    print(f\"Test AP Score: {test_ap:.4f}\")\n",
    "\n",
    "    # Plotting the results\n",
    "    plot_results(epochs, train_losses, val_aps, learning_rates)\n",
    "\n",
    "# Task 4: Draw the molecule represented by peptides_train[0]\n",
    "def draw_molecule(data, def_col=0):\n",
    "    G = pyg.utils.to_networkx(data, to_undirected=True)\n",
    "    node_features = data.x.numpy()\n",
    "    edge_index = data.edge_index.numpy()\n",
    "    edge_attr = data.edge_attr.numpy()\n",
    "    bond_types = edge_attr[:, 0].astype(int)\n",
    "    atom_types = None\n",
    "    atom_type_indices = None\n",
    "    for i, (u, v) in enumerate(zip(edge_index[0], edge_index[1])):\n",
    "        G.edges[u, v]['bond_type'] = bond_types[i]\n",
    "    if def_col == 0:\n",
    "        atom_types = {\n",
    "            5: 'C',\n",
    "            6: 'N',\n",
    "            7: 'O',\n",
    "        }\n",
    "        atom_type_indices = node_features[:, def_col].astype(int)\n",
    "    elif def_col == 2:\n",
    "        atom_types = {4: 'C', 3: 'O', 1: 'N'}\n",
    "        atom_type_indices = node_features[:, def_col].astype(int)\n",
    "    elif def_col == 4:\n",
    "        atom_types = {1: 'C', 0: 'O', 2: 'N'}\n",
    "        atom_type_indices = node_features[:, def_col].astype(int)\n",
    "    bond_color_mapping = {\n",
    "        0: 'black',\n",
    "        1: 'blue',\n",
    "        3: 'red',\n",
    "    }\n",
    "    edges = list(G.edges())\n",
    "    edge_colors = []\n",
    "    for u, v in edges:\n",
    "        bond_type = G.edges[u, v]['bond_type']\n",
    "        color = bond_color_mapping.get(bond_type, 'green')\n",
    "        edge_colors.append(color)\n",
    "    labels = {i: atom_types.get(atom_type_indices[i], 'X') for i in range(atom_type_indices.shape[0])}\n",
    "    size=12\n",
    "    plt.figure(figsize=(size, size))\n",
    "    pos = nx.kamada_kawai_layout(G, scale=5)\n",
    "    nx.draw(\n",
    "        G, pos,\n",
    "        with_labels=False,\n",
    "        node_size=50,\n",
    "        node_color='lightblue',\n",
    "        edgelist=edges,\n",
    "        edge_color=edge_colors,\n",
    "        width=1.5\n",
    "    )\n",
    "    nx.draw_networkx_labels(\n",
    "        G, pos,\n",
    "        labels=labels,\n",
    "        font_size=6,\n",
    "        font_weight='bold'\n",
    "    )\n",
    "    plt.title('Molecule Visualization of peptides_train[0]')\n",
    "    plt.axis('off')\n",
    "    plt.savefig('Molecule_Visualization.png')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load dataset and create data loaders\n",
    "    # Replace LRGBDataset with an appropriate dataset loader if needed\n",
    "    # Here, I'll assume you're using a custom dataset similar to TUDataset\n",
    "\n",
    "    try:\n",
    "        dataset = pyg.datasets.LRGBDataset(root='dataset/peptides-func', name=\"Peptides-func\")\n",
    "    except AttributeError:\n",
    "        # If LRGBDataset is not available, use a placeholder\n",
    "        # Replace this with the actual dataset loader you're using\n",
    "        print(\"LRGBDataset not found. Please replace with the actual dataset loader.\")\n",
    "        dataset = TUDataset(root='dataset/Mutagenicity', name='Mutagenicity')\n",
    "\n",
    "    # Check if dataset has splits; if not, create them manually\n",
    "    if hasattr(dataset, 'train_val_test_idx'):\n",
    "        peptides_train = dataset[dataset.train_val_test_idx['train']]\n",
    "        peptides_val = dataset[dataset.train_val_test_idx['val']]\n",
    "        peptides_test = dataset[dataset.train_val_test_idx['test']]\n",
    "    else:\n",
    "        # Create train, val, test splits manually\n",
    "        num_train = int(0.8 * len(dataset))\n",
    "        num_val = int(0.1 * len(dataset))\n",
    "        num_test = len(dataset) - num_train - num_val\n",
    "        peptides_train, peptides_val, peptides_test = torch.utils.data.random_split(dataset, [num_train, num_val, num_test])\n",
    "\n",
    "    batch_size = 32\n",
    "    train_loader = pyg.loader.DataLoader(peptides_train, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = pyg.loader.DataLoader(peptides_val, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = pyg.loader.DataLoader(peptides_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Check number of classes and label distribution\n",
    "    if hasattr(dataset, 'num_tasks'):\n",
    "        num_classes = dataset.num_tasks\n",
    "    elif hasattr(dataset, 'num_classes'):\n",
    "        num_classes = dataset.num_classes\n",
    "    else:\n",
    "        # Assume binary classification if not specified\n",
    "        num_classes = 1\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "    all_labels = np.concatenate([data.y.numpy() for data in dataset], axis=0)\n",
    "    label_distribution = np.mean(all_labels, axis=0)\n",
    "    print(f\"Label distribution: {label_distribution}\")\n",
    "\n",
    "    # Run the main training loop\n",
    "    main(epochs=300, lr=0.001, hidden_features=32)\n",
    "\n",
    "    # Draw the molecule for Task 4\n",
    "    if len(peptides_train) > 0:\n",
    "        draw_molecule(peptides_train[0])\n",
    "    else:\n",
    "        print(\"Training set is empty. Cannot draw a molecule.\")\n"
   ],
   "id": "818a486a6ed6da62",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of classes: 10\n",
      "Label distribution: [0.08884393 0.03540881 0.06419571 0.06226432 0.6272418  0.19755358\n",
      " 0.10687023 0.18412581 0.01995769 0.2598179 ]\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 272/272 [01:44<00:00,  2.61it/s]\n",
      "Evaluating: 100%|██████████| 34/34 [00:09<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3689, Validation AP Score: 0.2334, Learning Rate: 0.001000\n",
      "Epoch 2/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 272/272 [01:40<00:00,  2.70it/s]\n",
      "Evaluating: 100%|██████████| 34/34 [00:10<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3523, Validation AP Score: 0.2331, Learning Rate: 0.001000\n",
      "Epoch 3/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 272/272 [01:38<00:00,  2.76it/s]\n",
      "Evaluating: 100%|██████████| 34/34 [00:10<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3516, Validation AP Score: 0.2202, Learning Rate: 0.001000\n",
      "Epoch 4/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 272/272 [01:37<00:00,  2.78it/s]\n",
      "Evaluating: 100%|██████████| 34/34 [00:10<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3424, Validation AP Score: 0.2184, Learning Rate: 0.001000\n",
      "Epoch 5/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 272/272 [01:55<00:00,  2.35it/s]\n",
      "Evaluating: 100%|██████████| 34/34 [00:12<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3375, Validation AP Score: 0.2168, Learning Rate: 0.001000\n",
      "Epoch 6/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 272/272 [02:00<00:00,  2.26it/s]\n",
      "Evaluating: 100%|██████████| 34/34 [00:12<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3326, Validation AP Score: 0.2116, Learning Rate: 0.001000\n",
      "Epoch 7/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 32/272 [00:14<01:45,  2.28it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 506\u001B[0m\n\u001B[0;32m    503\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLabel distribution: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlabel_distribution\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    505\u001B[0m \u001B[38;5;66;03m# Run the main training loop\u001B[39;00m\n\u001B[1;32m--> 506\u001B[0m main(epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m300\u001B[39m, lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m, hidden_features\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m)\n\u001B[0;32m    508\u001B[0m \u001B[38;5;66;03m# Draw the molecule for Task 4\u001B[39;00m\n\u001B[0;32m    509\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(peptides_train) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "Cell \u001B[1;32mIn[7], line 386\u001B[0m, in \u001B[0;36mmain\u001B[1;34m(epochs, lr, hidden_features)\u001B[0m\n\u001B[0;32m    384\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m    385\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 386\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m train(model, train_loader, optimizer, loss_fn)\n\u001B[0;32m    387\u001B[0m     val_ap \u001B[38;5;241m=\u001B[39m evaluate(model, val_loader)\n\u001B[0;32m    388\u001B[0m     train_losses\u001B[38;5;241m.\u001B[39mappend(train_loss)\n",
      "Cell \u001B[1;32mIn[7], line 288\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, loader, optimizer, loss_fn)\u001B[0m\n\u001B[0;32m    286\u001B[0m batch\u001B[38;5;241m.\u001B[39medge_attr \u001B[38;5;241m=\u001B[39m batch\u001B[38;5;241m.\u001B[39medge_attr\u001B[38;5;241m.\u001B[39mfloat()  \u001B[38;5;66;03m# Convert edge attributes to float\u001B[39;00m\n\u001B[0;32m    287\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m--> 288\u001B[0m out \u001B[38;5;241m=\u001B[39m model(batch\u001B[38;5;241m.\u001B[39mx, batch\u001B[38;5;241m.\u001B[39medge_index, batch\u001B[38;5;241m.\u001B[39medge_attr, batch\u001B[38;5;241m.\u001B[39mbatch, batch)\n\u001B[0;32m    289\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(out, batch\u001B[38;5;241m.\u001B[39my\u001B[38;5;241m.\u001B[39mfloat())\n\u001B[0;32m    290\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[1;32mIn[7], line 222\u001B[0m, in \u001B[0;36mGNNWithVirtualNodeAndGINEAndTransformer.forward\u001B[1;34m(self, x, edge_index, edge_attr, batch, data)\u001B[0m\n\u001B[0;32m    215\u001B[0m sub_data \u001B[38;5;241m=\u001B[39m pyg\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mData(\n\u001B[0;32m    216\u001B[0m     x\u001B[38;5;241m=\u001B[39mx[node_idx],\n\u001B[0;32m    217\u001B[0m     edge_index\u001B[38;5;241m=\u001B[39msub_edge_index,\n\u001B[0;32m    218\u001B[0m     edge_attr\u001B[38;5;241m=\u001B[39msub_edge_attr\n\u001B[0;32m    219\u001B[0m )\n\u001B[0;32m    221\u001B[0m \u001B[38;5;66;03m# Compute Positional Encodings for the sub-graph\u001B[39;00m\n\u001B[1;32m--> 222\u001B[0m lap_pe \u001B[38;5;241m=\u001B[39m compute_laplace_pe(sub_data, num_eigenvec\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlap_pe_dim)\n\u001B[0;32m    223\u001B[0m rwse \u001B[38;5;241m=\u001B[39m compute_rwse(sub_data, walk_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrwse_dim)\n\u001B[0;32m    225\u001B[0m \u001B[38;5;66;03m# Apply SignNet to LapPE\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[7], line 78\u001B[0m, in \u001B[0;36mcompute_laplace_pe\u001B[1;34m(data, num_eigenvec)\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_laplace_pe\u001B[39m(data, num_eigenvec\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m):\n\u001B[1;32m---> 78\u001B[0m     G \u001B[38;5;241m=\u001B[39m to_networkx(data, to_undirected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     79\u001B[0m     A \u001B[38;5;241m=\u001B[39m nx\u001B[38;5;241m.\u001B[39madjacency_matrix(G)\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mfloat\u001B[39m)\n\u001B[0;32m     80\u001B[0m     num_nodes \u001B[38;5;241m=\u001B[39m A\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch_geometric\\utils\\convert.py:171\u001B[0m, in \u001B[0;36mto_networkx\u001B[1;34m(data, node_attrs, edge_attrs, graph_attrs, to_undirected, to_multi, remove_self_loops)\u001B[0m\n\u001B[0;32m    168\u001B[0m         G\u001B[38;5;241m.\u001B[39madd_node(start \u001B[38;5;241m+\u001B[39m i, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mnode_kwargs)\n\u001B[0;32m    170\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m edge_store \u001B[38;5;129;01min\u001B[39;00m data\u001B[38;5;241m.\u001B[39medge_stores:\n\u001B[1;32m--> 171\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, (v, w) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(edge_store\u001B[38;5;241m.\u001B[39medge_index\u001B[38;5;241m.\u001B[39mt()\u001B[38;5;241m.\u001B[39mtolist()):\n\u001B[0;32m    172\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m to_undirected_upper \u001B[38;5;129;01mand\u001B[39;00m v \u001B[38;5;241m>\u001B[39m w:\n\u001B[0;32m    173\u001B[0m             \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6c9cce987edb0a51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "98992f60c0c48494"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
