{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b9533f0-c800-4daa-b8cb-505ed7f4df2b",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "Due:  Tue December 3, 8:00am"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44773582-50fe-4d66-ba8e-03a368b350ea",
   "metadata": {},
   "source": [
    "## GPS and Hyperparameters\n",
    "\n",
    "This exercise consists of two parts: first, you are to combine global transformer attention (from the last exercise) with message-passing (from the second exercise). It is completely up to you how you combine those aspects, alternating between the two seems to be one of the best available options though. You may use (pure) message-passing layers from pytorch-geometric for this exercise (but obviously not layers like GPSConv that already combine things - especially since GPSConv differs significantly from the architecture in the GPS paper...).\n",
    "\n",
    "The second part of the exercise is to find a good model (with hyperparameters) for peptides-func. For this task, I want you to use the tool weights&biases (wandb.ai) and their \"sweep\" functionality. You can find example code for this below. Since we do not have access to your wandb accounts, please provide screenshots of your results and verify that these models are indeed good.\n",
    "\n",
    "For the hyperparameter tuning, you must perform this on your hybrid architecture. It might be interesting to see in how far the results (which parameters are important etc) differ between pure transformers, pure message-passing (possibly with VN), and hybrid approaches, although such an evaluation is not necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33633a0d-3859-4d10-b3f4-d27c390a5e5c",
   "metadata": {},
   "source": [
    "## Hybrid GPS-like architecture"
   ]
  },
  {
   "cell_type": "code",
   "id": "dc8a2d74-2089-47eb-9f61-df4f8c2ee9d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T12:55:01.844939Z",
     "start_time": "2024-12-02T12:54:56.159163Z"
    }
   },
   "source": [
    "# your model code goes here\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as pyg\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class GINELayerWithVN(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, edge_dim):\n",
    "        super(GINELayerWithVN, self).__init__(aggr='add')  # \"Add\" aggregation.\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(out_channels, out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(out_channels, out_channels)\n",
    "        )\n",
    "        self.edge_encoder = torch.nn.Linear(edge_dim, out_channels)\n",
    "        # Remove node_encoder from here\n",
    "        self.virtual_node_mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(out_channels, out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(out_channels, out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.edge_encoder.weight)\n",
    "        for m in self.mlp:\n",
    "            if isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "        for m in self.virtual_node_mlp:\n",
    "            if isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, vn_embed, batch):\n",
    "        # x is already encoded via node_encoder in the main model\n",
    "        x = x.float()  # Ensure x is FloatTensor\n",
    "        edge_attr = edge_attr.float()  # Ensure edge_attr is FloatTensor\n",
    "        edge_attr = self.edge_encoder(edge_attr)\n",
    "\n",
    "        # Add virtual node embedding to node features\n",
    "        vn_expanded = vn_embed[batch]\n",
    "        x = x + vn_expanded\n",
    "\n",
    "        # Message Passing\n",
    "        out = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "        # Update node embeddings\n",
    "        out = self.mlp(out)\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        # Compute messages\n",
    "        return x_j + edge_attr\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out\n",
    "\n",
    "# Laplacian Positional Encodings (LapPE)\n",
    "def compute_laplace_pe(data, num_eigenvec=10):\n",
    "    G = to_networkx(data, to_undirected=True)\n",
    "    A = nx.adjacency_matrix(G).astype(float)\n",
    "    num_nodes = A.shape[0]\n",
    "    D = np.diag(np.array(A.sum(axis=1)).flatten())\n",
    "    L = D - A.todense()\n",
    "    L = torch.tensor(L, dtype=torch.float, device=device)\n",
    "    try:\n",
    "        eigenvalues, eigenvectors = torch.linalg.eigh(L)\n",
    "    except RuntimeError:\n",
    "        eigenvalues, eigenvectors = torch.symeig(L, eigenvectors=True)\n",
    "    available_eigenvec = eigenvectors.shape[1] - 1\n",
    "    actual_num_eigenvec = min(num_eigenvec, available_eigenvec)\n",
    "    eigenvectors = eigenvectors[:, 1:1 + actual_num_eigenvec]\n",
    "    if actual_num_eigenvec < num_eigenvec:\n",
    "        pad_size = num_eigenvec - actual_num_eigenvec\n",
    "        padding = torch.zeros(eigenvectors.shape[0], pad_size, device=device)\n",
    "        eigenvectors = torch.cat([eigenvectors, padding], dim=1)\n",
    "    return eigenvectors  # Shape: (num_nodes, num_eigenvec)\n",
    "\n",
    "# Random Walk Structural Embeddings (RWSE)\n",
    "def compute_rwse(data, walk_length=10):\n",
    "    G = to_networkx(data, to_undirected=True)\n",
    "    A = nx.adjacency_matrix(G).astype(float)\n",
    "    A = A.todense()\n",
    "    num_nodes = A.shape[0]\n",
    "    A = torch.tensor(A, dtype=torch.float, device=device)\n",
    "    rw_features = []\n",
    "    A_power = A.clone()\n",
    "    for _ in range(walk_length):\n",
    "        diag = torch.diagonal(A_power)\n",
    "        rw_features.append(diag)\n",
    "        A_power = torch.matmul(A_power, A)\n",
    "    rwse = torch.stack(rw_features, dim=1)  # (num_nodes, walk_length)\n",
    "    return rwse  # Shape: (num_nodes, walk_length)\n",
    "\n",
    "# SignNet to ensure sign invariance\n",
    "class SignNet(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(SignNet, self).__init__()\n",
    "        self.phi = nn.Sequential(\n",
    "            nn.Linear(in_dim, out_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.phi(x) + self.phi(-x)\n",
    "\n",
    "# Graph Transformer Layer with Masking\n",
    "class GraphTransformerLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, num_heads=4, dropout=0.1):\n",
    "        super(GraphTransformerLayer, self).__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim=in_dim, num_heads=num_heads, dropout=dropout)\n",
    "        self.linear1 = nn.Linear(in_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(out_dim, in_dim)\n",
    "        self.norm1 = nn.LayerNorm(in_dim)\n",
    "        self.norm2 = nn.LayerNorm(in_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, key_padding_mask=None):\n",
    "        # x: (sequence_length, batch_size, embed_dim)\n",
    "        attn_output, _ = self.self_attn(x, x, x, key_padding_mask=key_padding_mask)\n",
    "        x = x + attn_output\n",
    "        x = self.norm1(x)\n",
    "        linear_output = self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
    "        x = x + linear_output\n",
    "        x = self.norm2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Updated GNN Model with Virtual Node, GINE Layers, and Graph Transformer\n",
    "class GNNWithVirtualNodeAndGINEAndTransformer(torch.nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, edge_attr_dim, num_layers=5, lap_pe_dim=10, rwse_dim=10, num_heads=4):\n",
    "        super(GNNWithVirtualNodeAndGINEAndTransformer, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_features = hidden_features\n",
    "\n",
    "        # Node Encoder\n",
    "        self.node_encoder = nn.Linear(in_features, hidden_features)\n",
    "\n",
    "        \n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.transformer_layers = nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            self.convs.append(GINELayerWithVN(\n",
    "                in_channels=hidden_features,\n",
    "                out_channels=hidden_features,\n",
    "                edge_dim=edge_attr_dim\n",
    "            ))\n",
    "            self.transformer_layers.append(GraphTransformerLayer(hidden_features, hidden_features, num_heads=num_heads))\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        self.virtual_node_embedding = torch.nn.Embedding(1, hidden_features)\n",
    "        torch.nn.init.constant_(self.virtual_node_embedding.weight.data, 0)\n",
    "\n",
    "        self.mlp_virtual_node = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_features, hidden_features),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_features, hidden_features),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Positional Encodings\n",
    "        self.lap_pe_dim = lap_pe_dim\n",
    "        self.rwse_dim = rwse_dim\n",
    "        self.lap_pe_linear = nn.Linear(hidden_features, hidden_features)\n",
    "        self.rwse_linear = nn.Linear(rwse_dim, hidden_features)\n",
    "        self.signnet = SignNet(lap_pe_dim, hidden_features)\n",
    "\n",
    "        \n",
    "\n",
    "        self.fc = torch.nn.Linear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch, data):\n",
    "        # Apply node_encoder first\n",
    "        x = self.node_encoder(x)  # [num_nodes, hidden_features]\n",
    "        # Initialize positional encodings tensor\n",
    "        pos_enc = torch.zeros_like(x).to(device)  # [num_nodes, hidden_features]\n",
    "\n",
    "        # Iterate over each graph in the batch\n",
    "        num_graphs = batch.max().item() + 1\n",
    "        for graph_id in range(num_graphs):\n",
    "            mask = (batch == graph_id)\n",
    "            num_nodes_graph = mask.sum().item()\n",
    "\n",
    "            # Extract node indices for the current graph\n",
    "            node_idx = torch.where(batch == graph_id)[0]\n",
    "\n",
    "            # Extract subgraph using pyg.utils.subgraph\n",
    "            sub_edge_index, sub_edge_attr = pyg.utils.subgraph(\n",
    "                node_idx,\n",
    "                edge_index,\n",
    "                edge_attr,\n",
    "                relabel_nodes=True,\n",
    "                num_nodes=x.size(0)\n",
    "            )\n",
    "\n",
    "            # Create sub_data\n",
    "            sub_data = pyg.data.Data(\n",
    "                x=x[node_idx],\n",
    "                edge_index=sub_edge_index,\n",
    "                edge_attr=sub_edge_attr\n",
    "            )\n",
    "\n",
    "            # Compute Positional Encodings for the sub-graph\n",
    "            lap_pe = compute_laplace_pe(sub_data, num_eigenvec=self.lap_pe_dim)\n",
    "            rwse = compute_rwse(sub_data, walk_length=self.rwse_dim)\n",
    "\n",
    "            # Apply SignNet to LapPE\n",
    "            lap_pe = self.signnet(lap_pe)  # [num_nodes_graph, hidden_features]\n",
    "\n",
    "            # Linear transformation\n",
    "            lap_pe = self.lap_pe_linear(lap_pe)  # [num_nodes_graph, hidden_features]\n",
    "            rwse = self.rwse_linear(rwse)        # [num_nodes_graph, hidden_features]\n",
    "\n",
    "            # Combine positional encodings\n",
    "            graph_pos_enc = lap_pe + rwse  # [num_nodes_graph, hidden_features]\n",
    "\n",
    "            # Assign to pos_enc\n",
    "            pos_enc[node_idx] = graph_pos_enc  # [num_nodes, hidden_features]\n",
    "\n",
    "        # Add positional encodings to node features\n",
    "        x = x + pos_enc  # [num_nodes, hidden_features]\n",
    "\n",
    "        # Initialize virtual node embedding\n",
    "        batch_size = num_graphs\n",
    "        vn_embed = self.virtual_node_embedding.weight.repeat(batch_size, 1)  # [batch_size, hidden_features]\n",
    "\n",
    "        for conv, transformer in zip(self.convs, self.transformer_layers):\n",
    "            x = conv(x, edge_index, edge_attr, vn_embed, batch)  # [num_nodes, hidden_features]\n",
    "            x = F.relu(x)\n",
    "\n",
    "            # Update virtual node embedding\n",
    "            vn_aggr = global_mean_pool(x, batch)  # [batch_size, hidden_features]\n",
    "            vn_embed = vn_embed + self.mlp_virtual_node(vn_aggr)  # [batch_size, hidden_features]\n",
    "             # Prepare for Graph Transformer\n",
    "            # Group node features by graph and pad\n",
    "            x_padded, mask = pyg.utils.to_dense_batch(x, batch)  # x_padded: [batch_size, max_num_nodes, hidden_features]\n",
    "\n",
    "            # Transpose to match expected input of Transformer\n",
    "            x_padded = x_padded.transpose(0, 1)  # x_padded: [max_num_nodes, batch_size, hidden_features]\n",
    "\n",
    "            # mask remains of shape [batch_size, max_num_nodes], which matches key_padding_mask\n",
    "            # Invert mask for key_padding_mask (True indicates positions to be masked)\n",
    "            key_padding_mask = ~mask  # [batch_size, max_num_nodes]\n",
    "            x_padded = transformer(x_padded, key_padding_mask=key_padding_mask)\n",
    "\n",
    "            # Transpose back\n",
    "            x_padded = x_padded.transpose(0, 1)  # x_padded: [batch_size, max_num_nodes, hidden_features]\n",
    "\n",
    "            # Flatten x_padded back to x\n",
    "            x = x_padded[mask]  # x: [num_nodes, hidden_features]\n",
    "\n",
    "\n",
    "        # Apply global mean pooling\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_features]\n",
    "        x = self.fc(x)  # [batch_size, out_features]\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "625a8487-01eb-46c2-ace6-7211b900b406",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T12:55:01.849133Z",
     "start_time": "2024-12-02T12:55:01.846944Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "e53b0ec0-7936-4b9c-884f-b126418135f5",
   "metadata": {},
   "source": [
    "# WandB hyperparameter tuning example code"
   ]
  },
  {
   "cell_type": "code",
   "id": "10328b2a-634d-4c8e-93a2-ae255ae1b28a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T12:55:01.853352Z",
     "start_time": "2024-12-02T12:55:01.850194Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch_geometric as pyg\n",
    "import torch_scatter\n",
    "import copy"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "59a8fe3f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Before using wandb, you need to create an account. Then you can login by pasting your API key when prompted. (just the key, nothing else)"
   ]
  },
  {
   "cell_type": "code",
   "id": "aba8bfcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T12:55:03.647894Z",
     "start_time": "2024-12-02T12:55:01.854356Z"
    }
   },
   "source": [
    "import wandb\n",
    "wandb.login()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: mak84271. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "652f0fe4-eef7-4f8d-9b1a-93f66d72839a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T12:55:03.654343Z",
     "start_time": "2024-12-02T12:55:03.649901Z"
    }
   },
   "source": [
    "# find device\n",
    "if torch.cuda.is_available(): # NVIDIA\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available(): # apple M1/M2\n",
    "    device = torch.device('mps') \n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "f973d525",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T12:55:04.388843Z",
     "start_time": "2024-12-02T12:55:03.655348Z"
    }
   },
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "\n",
    "\n",
    "class LocalPlanetoid(Planetoid):\n",
    "    def download(self):\n",
    "        # Skip the downloading step since files are already present locally\n",
    "        print(\"Skipping download step - using local files.\")\n",
    "\n",
    "# Use the custom loader\n",
    "cora = LocalPlanetoid(root='./dataset/cora', name='Cora')\n",
    "\n",
    "\n",
    "cora_graph = torch.load('cora.pt')\n",
    "cora_dense_adj = pyg.utils.to_dense_adj(cora_graph.edge_index).to(device)\n",
    "# cora_graph.x = cora_graph.x.unsqueeze(0) # Add an empty batch dimension. I needed that for compatibility with MolHIV later.\n",
    "cora_graph = cora_graph.to(device)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dadoi\\AppData\\Local\\Temp\\ipykernel_31584\\2945180447.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cora_graph = torch.load('cora.pt')\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cora.pt'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 14\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# Use the custom loader\u001B[39;00m\n\u001B[0;32m     11\u001B[0m cora \u001B[38;5;241m=\u001B[39m LocalPlanetoid(root\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./dataset/cora\u001B[39m\u001B[38;5;124m'\u001B[39m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCora\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 14\u001B[0m cora_graph \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcora.pt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     15\u001B[0m cora_dense_adj \u001B[38;5;241m=\u001B[39m pyg\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mto_dense_adj(cora_graph\u001B[38;5;241m.\u001B[39medge_index)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# cora_graph.x = cora_graph.x.unsqueeze(0) # Add an empty batch dimension. I needed that for compatibility with MolHIV later.\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\serialization.py:1319\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1316\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m   1317\u001B[0m     pickle_load_args[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1319\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _open_file_like(f, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[0;32m   1320\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[0;32m   1321\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[0;32m   1322\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[0;32m   1323\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[0;32m   1324\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\serialization.py:659\u001B[0m, in \u001B[0;36m_open_file_like\u001B[1;34m(name_or_buffer, mode)\u001B[0m\n\u001B[0;32m    657\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[0;32m    658\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[1;32m--> 659\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _open_file(name_or_buffer, mode)\n\u001B[0;32m    660\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    661\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\serialization.py:640\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[1;34m(self, name, mode)\u001B[0m\n\u001B[0;32m    639\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[1;32m--> 640\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mopen\u001B[39m(name, mode))\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'cora.pt'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "39becd27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T12:56:19.661021Z",
     "start_time": "2024-12-02T12:56:19.653798Z"
    }
   },
   "source": [
    "class GCNLayer(torch.nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, activation=torch.nn.functional.relu):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.activation = activation\n",
    "        self.W: torch.Tensor = torch.nn.Parameter(torch.zeros(in_features, out_features))\n",
    "        torch.nn.init.kaiming_normal_(self.W) \n",
    "\n",
    "    def forward(self, H: torch.Tensor, edge_index: torch.Tensor):\n",
    "        out = H.clone()\n",
    "        out += torch_scatter.scatter_add(H[edge_index[0]], edge_index[1], dim=0)\n",
    "        out = out.matmul(self.W)\n",
    "        if self.activation:\n",
    "            out = self.activation(out)\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "baea114a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T12:56:20.492897Z",
     "start_time": "2024-12-02T12:56:20.487639Z"
    }
   },
   "source": [
    "def get_accuracy(model, cora, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(cora_graph.x, cora_graph.edge_index)\n",
    "    correct = (outputs[mask].argmax(-1) == cora_graph.y[mask]).sum()\n",
    "    return int(correct) / int(mask.sum())"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "a6b356e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T12:56:20.834799Z",
     "start_time": "2024-12-02T12:56:20.828759Z"
    }
   },
   "source": [
    "class GraphNet(torch.nn.Module):\n",
    "    def __init__(self, in_features:int, out_features:int, hidden_features:int, activation=torch.nn.functional.relu, dropout=0.1):\n",
    "        super(GraphNet, self).__init__()\n",
    "        self.activation = activation\n",
    "        if dropout>0:\n",
    "            self.dropout = torch.nn.Dropout(dropout)\n",
    "        else: \n",
    "            self.dropout = torch.nn.Identity()\n",
    "\n",
    "        self.layer_1 = GCNLayer(in_features=in_features, out_features=hidden_features)\n",
    "        self.layer_2 = GCNLayer(in_features=hidden_features, out_features=hidden_features, activation=self.activation)\n",
    "        self.layer_3 = GCNLayer(in_features=hidden_features, out_features=hidden_features, activation=self.activation)\n",
    "        self.dense1 = torch.nn.Linear(in_features=hidden_features, out_features=hidden_features)\n",
    "        self.dense2 = torch.nn.Linear(in_features=hidden_features, out_features=out_features)\n",
    "\n",
    "    def forward(self, H: torch.Tensor, edge_index: torch.Tensor):\n",
    "        out = self.layer_1(H, edge_index)\n",
    "        out = self.dropout(out)\n",
    "        out = self.layer_2(out, edge_index)\n",
    "        out = self.dropout(out)\n",
    "        H = self.layer_3(out, edge_index)\n",
    "        H = self.dropout(out)\n",
    "        out = self.dense1(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.dense2(out)\n",
    "        # H = torch.softmax(H, dim=-1)\n",
    "        # out = torch.nn.functional.softmax(out, dim=1)\n",
    "        return out\n",
    "\n",
    "        "
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "38c03c9a",
   "metadata": {},
   "source": [
    "## WandB train function\n",
    "\n",
    "We make a few changes to our train function to enable wandb logging of hyperparameters and metrics. The train function is written to allow both manual runs and hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "id": "2071964d",
   "metadata": {},
   "source": [
    "def train(config=None, project=None, notes=None):\n",
    "\n",
    "    with wandb.init(config=config, project=project, notes=notes): # Initialize a new wandb run\n",
    "        # By passing our config through wandb,\n",
    "        # a) it is automatically logged\n",
    "        # b) we can use wandb sweeps to optimize hyperparameters\n",
    "        config = wandb.config \n",
    "\n",
    "        model = GraphNet(\n",
    "            in_features=cora_graph.num_features, \n",
    "            out_features=cora.num_classes, \n",
    "            hidden_features=config.hidden_features, \n",
    "            dropout=config.dropout).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs, eta_min=0)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        best_model = None\n",
    "        best_val_acc = 0\n",
    "        best_epoch = 0\n",
    "\n",
    "        for epoch in range(config.epochs):\n",
    "            \n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(cora_graph.x, cora_graph.edge_index) # we run on everything\n",
    "\n",
    "            loss = criterion(outputs[cora_graph.train_mask], cora_graph.y[cora_graph.train_mask]) # but only propagate the loss for the train labels\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step() # update parameters\n",
    "            scheduler.step() # update the learning rate once per epoch\n",
    "\n",
    "            val_acc = get_accuracy(model, cora_graph, cora_graph.val_mask)\n",
    "            wandb.log({\"val_acc\": val_acc, \"loss\": loss.item()})\n",
    "\n",
    "            if epoch % 10 == 0 and not wandb.run.sweep_id:\n",
    "                # Only print information on individual runs, not on sweeps\n",
    "                print(f\"Epoch {epoch}, Loss: {loss.item()}, Val accuracy: {val_acc}\")\n",
    "\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_epoch = epoch\n",
    "                best_model = copy.deepcopy(model)\n",
    "\n",
    "    return best_model, best_epoch, best_val_acc\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b173ddcf",
   "metadata": {},
   "source": [
    "## Manual training runs\n",
    "\n",
    "With wandb, you can still manually run your training loop with different hyperparameters as you are used to."
   ]
  },
  {
   "cell_type": "code",
   "id": "5d47a66b",
   "metadata": {},
   "source": [
    "best_model, best_model_epoch, best_val_acc = train(dict(\n",
    "    hidden_features=128,\n",
    "    lr=0.01,\n",
    "    dropout=0.1,\n",
    "    epochs=100\n",
    "), project=\"Cora_GraphNet\", notes=\"first trial\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c5b9ca8b008be13",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b0a0ad4db19a89dc",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cd346675",
   "metadata": {},
   "source": [
    "test_acc = get_accuracy(best_model, cora_graph, cora_graph.test_mask)\n",
    "print(f\"Test acc: {test_acc:.2f} (using model from epoch {best_model_epoch} with val acc {best_val_acc:.2})\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "49baed50",
   "metadata": {},
   "source": [
    "## Hyperparameter Search\n",
    "\n",
    "But you can also perform a hyperparameter search using wandb sweeps, by specifying a hyperparameter config"
   ]
  },
  {
   "cell_type": "code",
   "id": "be78650c",
   "metadata": {},
   "source": [
    "sweep_config = {\n",
    "    # hyperparameter search methods, e.g. grid, random\n",
    "    'method': 'random',\n",
    "\n",
    "    # metric to optimize\n",
    "    'metric': {\n",
    "        'name': 'val_acc',\n",
    "        'goal': 'maximize'   \n",
    "    },\n",
    "\n",
    "    # parameters to search\n",
    "    'parameters': {\n",
    "        'hidden_features': {\n",
    "            'values': [64, 128, 256]\n",
    "        },\n",
    "        'dropout': {\n",
    "            # a flat distribution between 0 and 0.1\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0.0,\n",
    "            'max': 0.5,\n",
    "        },\n",
    "        'lr': {\n",
    "            'values': [0.001, 0.0001, 0.00001]\n",
    "        },\n",
    "        'epochs': {\n",
    "            'values': [100, 200, 300]\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bdb6ca89",
   "metadata": {},
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"Cora_GraphNet\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4f32d0c7",
   "metadata": {},
   "source": [
    "You can click on the `Sweep URL` to get a nice visualization on how well different sets of hyperparameters perform and to see which are the best (click on the best run and then on Overview).\n",
    "\n",
    "The following cell performs 5 runs using the sweep configuration given above. You can call `wandb.agent` multiple times to produce more runs for the same sweep configuration."
   ]
  },
  {
   "cell_type": "code",
   "id": "57e588c3",
   "metadata": {},
   "source": [
    "wandb.agent(sweep_id, function=train, count=5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fb03889b",
   "metadata": {},
   "source": [
    "# Close the sweep, otherwise individual runs after the sweep will still be logged as part of it\n",
    "wandb.teardown() "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8cb5cd84-3220-44dc-a738-8b3702832dbb",
   "metadata": {},
   "source": [
    "# Cora dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "d415faef-ffc9-42bd-987c-5f1ba71a2b88",
   "metadata": {},
   "source": [
    "sweep_config = {\n",
    "    # hyperparameter search methods, e.g. grid, random\n",
    "    'method': 'random',\n",
    "\n",
    "    # metric to optimize\n",
    "    'metric': {\n",
    "        'name': 'val_acc',\n",
    "        'goal': 'maximize'   \n",
    "    },\n",
    "\n",
    "    # parameters to search\n",
    "    'parameters': {\n",
    "        'hidden_features': {\n",
    "            'values': [64, 128, 256]\n",
    "        },\n",
    "        'dropout': {\n",
    "            # a flat distribution between 0 and 0.1\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0.0,\n",
    "            'max': 0.5,\n",
    "        },\n",
    "        'lr': {\n",
    "            'values': [0.001, 0.0001, 0.00001]\n",
    "        },\n",
    "        'epochs': {\n",
    "            'values': [100, 200, 300]\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "431c19c8-90ed-439b-938d-24312f171667",
   "metadata": {},
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"Cora_Transformer\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f14cf483-5956-4273-b9b4-2603ee45f79e",
   "metadata": {},
   "source": [
    "GraphNet = GNNWithVirtualNodeAndGINEAndTransformer"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3053a8e9-0bbd-41ad-a7a2-a63190bd9574",
   "metadata": {},
   "source": [
    " in_features, hidden_features, out_features, edge_attr_dim, num_layers=5, lap_pe_dim=10, rwse_dim=10, num_heads=4)"
   ]
  },
  {
   "cell_type": "code",
   "id": "7b004c1c-bb75-4158-8303-0e7ba2a45aca",
   "metadata": {},
   "source": [
    "num_edge_features = cora.edge_attr.shape[1]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cb113abd-521a-46d0-ab55-6244c3d4a7e5",
   "metadata": {},
   "source": [
    "def train(config=None, project=None, notes=None):\n",
    "\n",
    "    with wandb.init(config=config, project=project, notes=notes): # Initialize a new wandb run\n",
    "        # By passing our config through wandb,\n",
    "        # a) it is automatically logged\n",
    "        # b) we can use wandb sweeps to optimize hyperparameters\n",
    "        config = wandb.config \n",
    "\n",
    "        model = GraphNet(\n",
    "            in_features=cora_graph.num_features,  \n",
    "            hidden_features=config.hidden_features,\n",
    "            out_features=cora.num_classes,\n",
    "            edge_attr_dim=num_edge_features\n",
    "            ).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs, eta_min=0)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        best_model = None\n",
    "        best_val_acc = 0\n",
    "        best_epoch = 0\n",
    "\n",
    "        for epoch in range(config.epochs):\n",
    "            \n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(cora_graph.x, cora_graph.edge_index) # we run on everything\n",
    "\n",
    "            loss = criterion(outputs[cora_graph.train_mask], cora_graph.y[cora_graph.train_mask]) # but only propagate the loss for the train labels\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step() # update parameters\n",
    "            scheduler.step() # update the learning rate once per epoch\n",
    "\n",
    "            val_acc = get_accuracy(model, cora_graph, cora_graph.val_mask)\n",
    "            wandb.log({\"val_acc\": val_acc, \"loss\": loss.item()})\n",
    "\n",
    "            if epoch % 10 == 0 and not wandb.run.sweep_id:\n",
    "                # Only print information on individual runs, not on sweeps\n",
    "                print(f\"Epoch {epoch}, Loss: {loss.item()}, Val accuracy: {val_acc}\")\n",
    "\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_epoch = epoch\n",
    "                best_model = copy.deepcopy(model)\n",
    "\n",
    "    return best_model, best_epoch, best_val_acc"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aecf74aa-6e33-40c3-836e-dfd1489009d7",
   "metadata": {},
   "source": [
    "wandb.agent(sweep_id, function=train, count=5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "45fe1ac8-e161-4044-a40f-d8eddb179d68",
   "metadata": {},
   "source": [
    " in_features, hidden_features, out_features, edge_attr_dim, num_layers=5, lap_pe_dim=10, rwse_dim=10, num_heads=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39370cb2b090800b",
   "metadata": {},
   "source": [
    "# Peptide dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "cbd5fcc05d90fdbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T12:56:29.881401Z",
     "start_time": "2024-12-02T12:56:27.904989Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as pyg\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import LRGBDataset\n",
    "import wandb\n",
    "import copy\n",
    "\n",
    "\n",
    "# Detect device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load the peptides-func dataset\n",
    "# Define a transform function\n",
    "def to_float(data):\n",
    "    data.x = data.x.float()\n",
    "    data.edge_attr = data.edge_attr.float()\n",
    "    return data\n",
    "\n",
    "# Load the dataset with the transform\n",
    "dataset = LRGBDataset(root='dataset/peptides-func', name='Peptides-func', transform=to_float)\n",
    "\n",
    "print(f'Dataset size: {len(dataset)}')\n",
    "\n",
    "# Determine the number of node features, edge features, and classes\n",
    "num_node_features = dataset.num_features\n",
    "num_edge_features = dataset[0].edge_attr.shape[1]\n",
    "num_classes = dataset.num_classes\n",
    "\n",
    "# Shuffle the dataset\n",
    "torch.manual_seed(42)\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "# Split the dataset\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "num_total = len(dataset)\n",
    "num_train = int(num_total * train_ratio)\n",
    "num_val = int(num_total * val_ratio)\n",
    "\n",
    "train_dataset = dataset[:num_train]\n",
    "val_dataset = dataset[num_train:num_train + num_val]\n",
    "test_dataset = dataset[num_train + num_val:]\n",
    "\n",
    "print(f'Train graphs: {len(train_dataset)}')\n",
    "print(f'Validation graphs: {len(val_dataset)}')\n",
    "print(f'Test graphs: {len(test_dataset)}')\n",
    "\n",
    "# Create data loaders\n",
    "def create_data_loader(dataset, batch_size, shuffle):\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "\n",
    "# We will create data loaders inside the train function\n",
    "# Your model class\n",
    "\n",
    "\n",
    "GraphNet = GNNWithVirtualNodeAndGINEAndTransformer\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Dataset size: 10873\n",
      "Train graphs: 8698\n",
      "Validation graphs: 1087\n",
      "Test graphs: 1088\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "b61567a17ff43090",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T12:56:29.891832Z",
     "start_time": "2024-12-02T12:56:29.881401Z"
    }
   },
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train(config=None, project=None, notes=None):\n",
    "    with wandb.init(config=config, project=project, notes=notes):\n",
    "        config = wandb.config\n",
    "\n",
    "        model = GraphNet(\n",
    "            in_features=num_node_features,\n",
    "            hidden_features=config.hidden_features,\n",
    "            out_features=num_classes,\n",
    "            edge_attr_dim=num_edge_features,\n",
    "            num_layers=config.num_layers,\n",
    "            lap_pe_dim=config.lap_pe_dim,\n",
    "            rwse_dim=config.rwse_dim,\n",
    "            num_heads=config.num_heads\n",
    "        ).to(device)\n",
    "\n",
    "        # Print the GPU memory allocated by PyTorch\n",
    "        print(f\"GPU memory allocated after model initialization: {torch.cuda.memory_allocated()} bytes\")\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs, eta_min=0)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        best_model = None\n",
    "        best_val_acc = 0\n",
    "        best_epoch = 0\n",
    "\n",
    "        # Create data loaders\n",
    "        train_loader = create_data_loader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "        val_loader = create_data_loader(val_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "        test_loader = create_data_loader(test_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "        for epoch in tqdm(range(config.epochs)):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            for data in train_loader:\n",
    "                data = data.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(data.x, data.edge_index, data.edge_attr, data.batch, data)\n",
    "                loss = criterion(outputs, data.y.squeeze())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            val_acc = evaluate(model, val_loader)\n",
    "            wandb.log({\"val_acc\": val_acc, \"loss\": total_loss / len(train_loader)})\n",
    "\n",
    "            if epoch % 10 == 0 and not wandb.run.sweep_id:\n",
    "                print(f\"Epoch {epoch}, Loss: {total_loss / len(train_loader):.4f}, Val accuracy: {val_acc:.4f}\")\n",
    "\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_epoch = epoch\n",
    "                best_model = copy.deepcopy(model)\n",
    "\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # Evaluate on test set\n",
    "        test_acc = evaluate(best_model, test_loader)\n",
    "        wandb.log({\"test_acc\": test_acc})\n",
    "\n",
    "        print(f\"Best Epoch: {best_epoch}, Best Validation Accuracy: {best_val_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "        return best_model, best_epoch, best_val_acc, test_acc\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "64b7de26f73826c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T12:56:29.899729Z",
     "start_time": "2024-12-02T12:56:29.891832Z"
    }
   },
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            outputs = model(data.x, data.edge_index, data.edge_attr, data.batch, data)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            #print(f\"preds shape: {preds.shape}, data.y shape: {data.y.squeeze().shape}, num_graphs: {data.num_graphs}\")\n",
    "\n",
    "            \n",
    "            # Convert one-hot encoded labels to class indices\n",
    "            true_classes = data.y.argmax(dim=1)  # Shape: [32]\n",
    "\n",
    "            # Compare predictions with true class indices\n",
    "            correct += (preds == true_classes).sum().item()\n",
    "            total += data.num_graphs\n",
    "    return correct / total\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "4b47e3c6688bb1cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T12:56:30.535731Z",
     "start_time": "2024-12-02T12:56:29.899729Z"
    }
   },
   "source": [
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'metric': {'name': 'val_acc', 'goal': 'maximize'},\n",
    "    'parameters': {\n",
    "        'hidden_features': {'values': [64, 128, 256]},\n",
    "        'num_layers': {'values': [3, 5, 7]},\n",
    "        'num_heads': {'values': [4, 8]},\n",
    "        'lap_pe_dim': {'values': [5, 10, 15]},\n",
    "        'rwse_dim': {'values': [5, 10, 15]},\n",
    "        'dropout': {'min': 0.0, 'max': 0.5},\n",
    "        'lr': {'min': 1e-4, 'max': 1e-2, 'distribution': 'log_uniform'},\n",
    "        'weight_decay': {'min': 0.0, 'max': 1e-4},\n",
    "        'batch_size': {'values': [16, 32, 64]},\n",
    "        'epochs': {'value': 100}\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project='peptides-func-hyperparameter-tuning')\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n",
      "wandb: WARNING To avoid this, please fix the sweep config schema violations below:\n",
      "wandb: WARNING   Violation 1. lr uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: lhl35pl1\n",
      "Sweep URL: https://wandb.ai/mak84271/peptides-func-hyperparameter-tuning/sweeps/lhl35pl1\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "3c5256d47b2847c3",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-02T12:56:30.535731Z"
    }
   },
   "source": [
    "wandb.login()  # Ensure you are logged in to WandB\n",
    "\n",
    "# Start the sweep agent\n",
    "wandb.agent(sweep_id, function=train)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 6fun1ank with config:\n",
      "wandb: \tbatch_size: 16\n",
      "wandb: \tdropout: 0.05960667915644807\n",
      "wandb: \tepochs: 100\n",
      "wandb: \thidden_features: 256\n",
      "wandb: \tlap_pe_dim: 10\n",
      "wandb: \tlr: 1.0096504713632417\n",
      "wandb: \tnum_heads: 8\n",
      "wandb: \tnum_layers: 7\n",
      "wandb: \trwse_dim: 10\n",
      "wandb: \tweight_decay: 6.791213641383701e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\dadoi\\DataspellProjects\\Graph_Machine_Learning\\wandb\\run-20241202_135632-6fun1ank</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mak84271/peptides-func-hyperparameter-tuning/runs/6fun1ank' target=\"_blank\">dutiful-sweep-1</a></strong> to <a href='https://wandb.ai/mak84271/peptides-func-hyperparameter-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/mak84271/peptides-func-hyperparameter-tuning/sweeps/lhl35pl1' target=\"_blank\">https://wandb.ai/mak84271/peptides-func-hyperparameter-tuning/sweeps/lhl35pl1</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/mak84271/peptides-func-hyperparameter-tuning' target=\"_blank\">https://wandb.ai/mak84271/peptides-func-hyperparameter-tuning</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mak84271/peptides-func-hyperparameter-tuning/sweeps/lhl35pl1' target=\"_blank\">https://wandb.ai/mak84271/peptides-func-hyperparameter-tuning/sweeps/lhl35pl1</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/mak84271/peptides-func-hyperparameter-tuning/runs/6fun1ank' target=\"_blank\">https://wandb.ai/mak84271/peptides-func-hyperparameter-tuning/runs/6fun1ank</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory allocated after model initialization: 19576320 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "10150d70055e40b9",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ca0ab47da7ef0170",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
